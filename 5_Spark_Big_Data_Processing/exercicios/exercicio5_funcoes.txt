Exercícios 5 - WithColumn 1/2

1. Criar um dataframe para ler o arquivo no HDFS /user/<nome/data/juros_selic/juros_selic

$ !hdfs dfs -cat "hdfs:///user/rafaella/data/juros_selic/juros_selic"
$ from pyspark.sql.functions import *
$ juros_df = spark.read.csv("hdfs:///user/rafaella/data/juros_selic/juros_selic", sep=";", header="true")
$ juros_df.show(5)

2. Alterar o formato do campo data para “MM/dd/yyyy”

#juros_data_unix = juros_df.withColumn("data", unix_timestamp(col("data"),"dd/MM/yyyy")).show(3)
#juros_data_americano = juros_data_unix.withColumn("data", from_unixtime("data","MM/dd/yyyy")).show(3)
ou
$ juros_data_americano = juros_df.withColumn("data", from_unixtime(unix_timestamp(col("data"),"dd/MM/yyyy"), "MM/dd/yyyy"))
$ juros_data_americano.show(3)

3. Com uso da função from_unixtime crie o campo “ano_unix”, com a informação do ano do campo data

$ juros_ano_unixtime = juros_data_americano.withColumn("ano_unix", from_unixtime(unix_timestamp(col("data"),"MM/dd/yyyy"), "yyyy"))
$ juros_ano_unixtime.show(3)

4. Com uso de substring crie o campo “ano_str”, com a informação do ano do campo data

$ juros_substring = juros_ano_unixtime.withColumn("ano_str", substring(col("data"), 7, 4))
juros_substring.show(3)

5. Com uso da função split crie o campo “ano_str”, com a informação do ano do campo data

$ juros_split = juros_substring.withColumn("ano_split", split(col("data"), "/").getItem(2))
$ juros_split.show(3) #Deixar somente o ano

6. Salvar no hdfs /user/rafaella/juros_selic_americano no formato CSV, incluindo o cabeçalho

$ juros_split.write.csv("hdfs:///user/rafaella//juros_selic_americano", header="true")

$ !hdfs dfs -ls "hdfs:///user/rafaella//juros_selic_americano"

------

Exercicios 5 - WithColumn 2/2

1. Criar um dataframe para ler o arquivo no HDFS /user/<nome/data/juros_selic/juros_selic

$ !hdfs dfs -cat "hdfs:///user/rafaella/data/juros_selic/juros_selic"

$ from pyspark.sql.functions import *
$ from pyspark.sql.types import *

$juros_selic = spark.read.csv("hdfs:///user/rafaella/data/juros_selic/juros_selic", header="true", sep=";")
juros_selic.show(3)

2. Agrupar todas as datas pelo ano em ordem decrescente e salvar a quantidade de meses ocorridos, o valor médio, mínimo e máximo do campo valor com a seguinte estrutura:

| Anual | Meses | Valor médio | Valor Mínimo | Valor Máximo |
| ----- | ----- | ----------- | ------------ | ------------ |
| 2019  | 2     | 00.00       | 00.00        | 00.00        |
| 2018  | 12    | 00.00       | 00.00        | 00.00        |
| 2017  | 12    | 00.00       | 00.00        | 00.00        |
| ...   | ...   | 00.00       | 00.00        | 00.00        |
| 1986  | 2     | 00.00       | 00.00        | 00.00        |

$ juros_ano = juros_selic.withColumn("ano", split(col("data"),"/").getItem(2)) #Separar ano
$ juros_valor = juros_ano.withColumn("valor", regexp_replace(col("valor"), "\,","\.").cast(FloatType())) #Substituir virgula por ponto e converter os valores para formato numérico com cast

$ juros_relatorio_anual = juros_valor.groupBy("ano").agg(count("ano").alias("meses"),
                                                 format_number(avg("valor"), 2).alias("valor medio"),
                                                 min("valor").alias("valor mínimo"),
                                                 max("valor").alias("valor máximo")).sort(desc("ano")).withColumnRenamed('ano', 'Anual')
$ juros_relatorio_anual.show()

3. Salvar no hdfs:///user/<nome>/relatorioAnual com compressão zlib e formato orc

$ juros_relatorio_anual.write.orc("hdfs:///user/cicero/relatorio_anual", compression="zlib")

$ !hdfs dfs -ls "hdfs:///user/cicero/relatorio_anual"
